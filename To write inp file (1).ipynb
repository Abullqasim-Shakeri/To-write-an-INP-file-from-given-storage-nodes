{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e002b67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "from copy import deepcopy\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display, clear_output\n",
    "from pyswmm import Simulation, Subcatchments, Nodes\n",
    "from scipy.interpolate import interp2d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "895928d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns all node IDs for given SWMM file\n",
    "def node_id (name):\n",
    "    with Simulation(name) as sim:\n",
    "        node_id = pd.DataFrame(columns=[\"Node_ID\", \"Elevation\"])\n",
    "        for node in Nodes(sim):\n",
    "            new_data = {\"Node_ID\": node.nodeid, \"Elevation\": node.invert_elevation, \"OUTFALL\":node.is_outfall()}\n",
    "            node_id = node_id.append(new_data, ignore_index=True)\n",
    "    return node_id\n",
    "\n",
    "# to find charachteristic of the cachtment a\n",
    "def subcatchments_char (name):\n",
    "    subcatchment_id = pd.DataFrame(columns=[\"Subcatchment_ID\", \"Area\",\"Imperv_percentage\", \"connected_to\", \"Connected_nodeid\"])\n",
    "    with Simulation(name) as sim:\n",
    "        subcatchments = Subcatchments(sim)\n",
    "        for subcatchment in subcatchments:\n",
    "            new_data = {\"Subcatchment_ID\": subcatchment.subcatchmentid, \"Area\": subcatchment.area,\"Imperv_percentage\":subcatchment.percent_impervious,  \"connected_to\": subcatchment.connection[0] , \"Connected_nodeid\":subcatchment.connection[1]}\n",
    "            subcatchment_id = subcatchment_id.append(new_data, ignore_index = True)\n",
    "    return(subcatchment_id)\n",
    "\n",
    "def total_imperv_area (name):\n",
    "    sub_char = subcatchments_char(name)\n",
    "    return sub_char.groupby('Connected_nodeid')[\"Area\"].sum().to_frame(name = 'connected catchment area [ha]').reset_index()\n",
    "\n",
    "\n",
    "# to find line number for a given phrase\n",
    "def line_num (name, phrase):\n",
    "    line_number = \"Phrase not found\"\n",
    "    a_file = open(name,\"r\")\n",
    "    for number, line in enumerate(a_file):\n",
    "        if phrase in line:\n",
    "            line_number = number\n",
    "            break\n",
    "            a_file.close()\n",
    "    return line_number\n",
    "\n",
    "\n",
    "#to delete specific range of lines in a file\n",
    "def del_line_range (name, starting_ling, ending_line):\n",
    "    with open(name, 'r+') as fp:\n",
    "        lines = fp.readlines()\n",
    "        fp.seek(0)\n",
    "        fp.truncate()\n",
    "        for number, line in enumerate(lines):\n",
    "            if number not in list(range(starting_ling, ending_line)):\n",
    "                fp.write(line)\n",
    "                \n",
    "def del_line (name, line_number):\n",
    "    lines = []\n",
    "    with open(name, 'r') as fp:\n",
    "        lines = fp.readlines()\n",
    "    with open(name, 'w') as fp:\n",
    "        for number, line in enumerate(lines):\n",
    "            if number != line_number:\n",
    "                fp.write(line)\n",
    "\n",
    "                \n",
    "# to check if the string exist in the file \n",
    "def check_if_string(name, string_to_search):\n",
    "    with open(name, 'r') as read_obj:\n",
    "        for line in read_obj:\n",
    "            if string_to_search in line:\n",
    "                return True\n",
    "    return False \n",
    "\n",
    "\n",
    "def search_string_betweentwo(name, string_to_search, minim, maxim):\n",
    "    line_nu = 0\n",
    "    line_number = 0\n",
    "    list_of_results = []\n",
    "    with open(name, 'r') as read_obj:\n",
    "        for line in read_obj:\n",
    "            line_number += 1\n",
    "            if string_to_search in line:\n",
    "                if minim<line_number < maxim:\n",
    "                    list_of_results.append((line_number))\n",
    "                    line_nu = line_number\n",
    "    return line_nu-1\n",
    "\n",
    "\n",
    "def linenumber_junction (name, string):\n",
    "    st= line_num(name, \"[JUNCTIONS]\")\n",
    "    en= line_num(name, \"[OUTFALLS]\")\n",
    "    return search_string_betweentwo (name, string, st, en)\n",
    "\n",
    "#add a new line in a certian location in a text file\n",
    "def insert_new_line (name, index, content):\n",
    "    with open(name, \"r\") as f:\n",
    "        contents = f.readlines()\n",
    "    contents.insert(index, \"\\n\")\n",
    "    contents.insert(index, content)\n",
    "    with open(name, \"w\") as f:\n",
    "        f.writelines(contents)\n",
    "\n",
    "        \n",
    "def insert_multiple_line (name, index, content):\n",
    "    ind = index\n",
    "    with open(name, \"r\") as f:\n",
    "        contents = f.readlines()\n",
    "    for num in content:\n",
    "        #contents.insert(ind, \"\\n\")\n",
    "        contents.insert(ind, num)\n",
    "        ind += 1\n",
    "    with open(name, \"w\") as f:\n",
    "        f.writelines(contents)\n",
    "        \n",
    "def select_data_range (name, fromm, to):\n",
    "    with open(name, 'r') as fp:\n",
    "        x = fp.readlines()[fromm:to]\n",
    "        return x\n",
    "\n",
    "# to find maximum flooding for one noode\n",
    "def node_max_flood (name, node_id):\n",
    "\n",
    "    flood = pd.DataFrame(columns=[\"Node_ID\", \"flood\"])\n",
    "    max_flood = pd.DataFrame(columns=[\"Node_ID\", \"flood\"])\n",
    "\n",
    "    with Simulation(name) as sim:\n",
    "        j = Nodes(sim)[str(node_id)]\n",
    "        for step in sim:\n",
    "            if j.flooding > 1:\n",
    "                j_flood = {\"Node_ID\": j.nodeid, \"flood\": j.flooding}\n",
    "                flood = flood.append(j_flood, ignore_index=True)\n",
    "    maxflood =  {\"Node_ID\": j.nodeid, \"flood\": flood['flood'].max() }\n",
    "    max_flood = max_flood.append(maxflood, ignore_index=True)\n",
    "    return max_flood\n",
    "\n",
    "\n",
    "# to add raingage path or name to swwm file\n",
    "def add_raingage (file_name, raingage_name):\n",
    "    del_line_range(file_name,line_num(file_name, \"[RAINGAGES]\")+1, line_num(file_name, \"[SUBCATCHMENTS]\") )\n",
    "    new_line = f\"LO VOLUME 0:05 1.0 FILE {raingage_name} LO MM \\n\"\n",
    "    insert_new_line(file_name, line_num(file_name, \"[RAINGAGES]\")+1, new_line)\n",
    "    \n",
    "    \n",
    "#to find maximum flood for all nodes\n",
    "def allnodes_max_flood (name):\n",
    "\n",
    "    all_nodes = node_id(name)\n",
    "    all_nodes_max_flood= pd.DataFrame(columns=[\"Node_ID\", \"flood\"])\n",
    "    for ind in all_nodes.index:\n",
    "        max_flood = node_max_flood(name, all_nodes['Node_ID'][ind])\n",
    "        all_nodes_max_flood = all_nodes_max_flood.append(max_flood, ignore_index=True)\n",
    "    all_nodes_max_flood=all_nodes_max_flood.dropna()\n",
    "    return all_nodes_max_flood\n",
    "\n",
    "\n",
    "#to convert selected object data type to a dataframe with float data type\n",
    "def to_dataframe_dtype (orig, dic_columns_dtype):\n",
    "    splited = []\n",
    "    for elem in orig:\n",
    "        splited.append(elem.split())\n",
    "    return pd.DataFrame(splited, columns = list(dic_columns_dtype.keys())).astype(dic_columns_dtype)\n",
    "\n",
    "\n",
    "def run_model(name):\n",
    "    with Simulation(name) as sim:\n",
    "        for step in sim:\n",
    "            pass\n",
    "        sim.report()\n",
    "\n",
    "        \n",
    "# to read maximum flood for all nodes from rpt file\n",
    "def read_max_flood (name_of_rpt_file):\n",
    "    run_model(name)\n",
    "    f= open(rpt, 'r')\n",
    "    lines= f.readlines()\n",
    "    idx_ini= line_num(name_of_rpt_file, 'Node Flooding Summary\\n' )\n",
    "    if check_if_string(name_of_rpt_file, \"Storage Volume Summary\"):\n",
    "        idx_end= line_num(name_of_rpt_file, \"Storage Volume Summary\")-1\n",
    "    else:\n",
    "        idx_end= line_num(name_of_rpt_file, 'Outfall Loading Summary\\n')-1\n",
    "    column_type = {'Node': str, 'HoursFlooded': float , 'Maximum_rate_LPS': float, \"days\": float, \"hours\": float, \"min\": float,  \"Total_flood_volume\": float, \"Maximum_ponded_depth_meters\": float}        \n",
    "    d = []\n",
    "    if lines[idx_ini+3] == '  No nodes were flooded.\\n':\n",
    "        d.append(0)\n",
    "        return pd.DataFrame(d, columns =['Total_flood_volume'])\n",
    "    else:\n",
    "        for i in select_data_range(name_of_rpt_file, idx_ini+10, idx_end):\n",
    "            d.append(i.replace(\":\", \" \"))\n",
    "            df = to_dataframe_dtype(d, column_type).dropna()\n",
    "            df[\"Total_flood_volume\"] = 1000000 * df[\"Total_flood_volume\"]\n",
    "    return df\n",
    "            \n",
    "\n",
    "\n",
    "def read_conduites (name):\n",
    "    f= open(name, 'r')\n",
    "    lines= f.readlines()\n",
    "    idx_ini= line_num(name, \"[CONDUITS]\" )+1\n",
    "    idx_end= line_num(name, \"[XSECTIONS]\")-1\n",
    "    if 'Name' in lines[idx_ini]:\n",
    "        idx_ini = idx_ini+3\n",
    "    d= []\n",
    "    for i in select_data_range(name, idx_ini, idx_end):\n",
    "        d.append(i.split())\n",
    "    column_type = {'Name': str, 'From_Node': str , 'To_Node': str, \"Lenght\": float, \"Roughness\": float, \"InOffset\": float,  \"OutOffset\": float, \"InitFlow\": float, \"Maxflow\":float}        \n",
    "    return pd.DataFrame(d, columns = list(column_type.keys())).astype(column_type)\n",
    "\n",
    "\n",
    "def find_all_paths (node_index):\n",
    "    index = node_index\n",
    "    f_path = []\n",
    "    ini = []\n",
    "    ini.append(conduites.loc[index][\"To_Node\"])\n",
    "    f_path.append(ini)\n",
    "    ind = 0\n",
    "    count = 0\n",
    "    n = 0\n",
    "    #to find all paths\n",
    "    while n<=len(f_path):\n",
    "        c = -1\n",
    "        for i in f_path: \n",
    "            c=c+1\n",
    "            if i[-1] in word_count:   \n",
    "                flow_from= []\n",
    "                if word_count [f_path[c][-1]] == 2:\n",
    "                    L2= f_path[c].copy()\n",
    "                    flow_from.append(conduites.loc[conduites.index[conduites['To_Node']== f_path[c][-1]]][\"From_Node\"].to_list())\n",
    "                    f_path[c].append(flow_from[0][0])\n",
    "                    L2.append(flow_from[0][1])\n",
    "                    f_path.append(L2)\n",
    "                elif word_count [f_path[c][-1]] == 1:\n",
    "                    flow_from.append(conduites.loc[conduites.index[conduites['To_Node']== f_path[c][-1]]][\"From_Node\"].to_list())\n",
    "                    f_path[c].append(flow_from[0][0])\n",
    "            else:\n",
    "                pass\n",
    "        n=n+1 \n",
    "    return(f_path)\n",
    "\n",
    "\n",
    "#to find th longest path and the total upstraim area\n",
    "def total_area_lenght (f_path, sub_area): \n",
    "    total_lenght= []\n",
    "    area_from =[]\n",
    "    area = []\n",
    "    for l in f_path:\n",
    "        lenghts = []\n",
    "        z=0\n",
    "        for n in l:\n",
    "            if n not in area_from:\n",
    "                area_from.append(n)\n",
    "                area.extend((sub_area.loc[sub_area.index[sub_area['Connected_nodeid']== n]][\"connected catchment area [ha]\"]))\n",
    "            if z != 0:\n",
    "                lenghts.extend((conduites.loc[conduites.index[conduites['From_Node']== n]][\"Lenght\"].to_list()))\n",
    "            z=z+1\n",
    "        lenghts_sum = sum(lenghts)\n",
    "        total_lenght.append(lenghts_sum)\n",
    "    total_lenght \n",
    "    area_from\n",
    "    sum(area)\n",
    "    total_lenght\n",
    "    longest_path = f_path[total_lenght.index(max(total_lenght))]\n",
    "    longest_path_lenght = max(total_lenght)\n",
    "    total_area= sum(area)\n",
    "    return (longest_path, longest_path_lenght, total_area)\n",
    "\n",
    "\n",
    "def total_area_lenght_all (name):\n",
    "    sub_area= total_imperv_area(name)\n",
    "    conduites = read_conduites(name)\n",
    "    word_count= pd.value_counts(conduites['To_Node'])\n",
    "    longest_path= []\n",
    "    longest_path_lenght = []\n",
    "    total_area = []  \n",
    "    for nodes in range(len(sub_area[\"Connected_nodeid\"])):\n",
    "        f_path = find_all_paths(nodes)\n",
    "        c = total_area_lenght(f_path, sub_area)\n",
    "        longest_path.append (c[0])\n",
    "        longest_path_lenght.append (c[1])\n",
    "        total_area.append (c[2])\n",
    "    return sub_area.assign(longest_path =longest_path, longest_path_lenght=longest_path_lenght, total_area = total_area)\n",
    "\n",
    "\n",
    "\n",
    "def rain_depth (return_period,rain_duration):\n",
    "    c_5 = pd.read_excel('C.Plauen.xlsx')\n",
    "    t_n = list(c_5.columns.values)\n",
    "    x = t_n[1:]\n",
    "    y = c_5[\"Return period Tn [a]:\"].to_list()\n",
    "    z = []\n",
    "    for index, row in c_5.iterrows():\n",
    "        z.append(list(row[1:]))\n",
    "    f = interp2d(x,y,z, kind = \"linear\", fill_value=\"-1\")\n",
    "    rain_depth = []\n",
    "    if rain_duration in y:\n",
    "        y_indx = y.index(rain_duration)+1\n",
    "    else:\n",
    "        y.append(rain_duration)\n",
    "        y.sort()\n",
    "        y_indx = y.index(rain_duration)+1\n",
    "    for i in y[:y_indx]:\n",
    "        rain_depth.append(f(return_period, i)[0])\n",
    "    return (y[:y_indx], rain_depth)\n",
    "\n",
    "\n",
    "def storage_area_design (safety_factor, return_period, rain_duration, hight):\n",
    "#input\n",
    "    #safety_factor = 1.2 klk\n",
    "    #return_period = 5\n",
    "    #rain_duration = 240\n",
    "\n",
    "    n = 1/return_period\n",
    "    travel_time = 20\n",
    "    \n",
    "    rain_depth_mm=rain_depth(return_period, rain_duration)\n",
    "    area_hectar =total_area_lenght_all(name)\n",
    "    volume = []\n",
    "    storage_area_m2 = []\n",
    "    for m in area_hectar[\"total_area\"]:\n",
    "        \n",
    "        runoff_volume_m3 = [i * m*10000/1000 for i in rain_depth_mm[1]]\n",
    "        #runoff_volume_m3 = [i * 81000/1000 for i in rain_depth_mm[1]]\n",
    "\n",
    "        q_ls= 2*m\n",
    "        q_m3m = q_ls*3.6/60\n",
    "        throttle_volume_m3 = [i * q_m3m for i in rain_depth_mm[0]]\n",
    "        travel_time_m = 20\n",
    "        f1 = 1-((1*10**-10*travel_time**3)-(8*10**-9*travel_time**2)+(1*10**-8*travel_time))*q_ls**3+((1.6*10**-8*travel_time**3)-(9.15*10**-7*travel_time**2)+(1.14*10**-6*travel_time))*q_ls**2+((1.8*10**-7*travel_time**3)-(1.25*10**-5*travel_time**2)+(1.56*10**-5*travel_time))*q_ls\n",
    "        attenuation_factor =  (0.6134*n+0.3866)*f1-(0.6134*n-0.6134)\n",
    "        #attenuation_factor = 0.98\n",
    "        \n",
    "        design_volume = np.subtract(np.array(runoff_volume_m3),np.array(throttle_volume_m3))*safety_factor*attenuation_factor\n",
    "        design_volume = design_volume.max()\n",
    "        area = design_volume/hight\n",
    "        storage_area_m2.append(area)\n",
    "        volume.append(design_volume)\n",
    "    return storage_area_m2\n",
    "\n",
    "\n",
    "#add storage section to .inp file if not existed before\n",
    "def add_to_inp (section, lower_section, to_add):\n",
    "    if not check_if_string(name, section):\n",
    "        insert_new_line(name,line_num(name, lower_section), section )\n",
    "    #add new STORAGE list to .inp file\n",
    "    del_line_range(name, line_num(name, section)+1, line_num(name, lower_section) )\n",
    "    insert_multiple_line(name, line_num(name, section)+1, to_add)\n",
    "    \n",
    "    \n",
    "    \n",
    "# read the file's contents\n",
    "def read_inp(name):\n",
    "    read_file = open(name,'r')\n",
    "    lines = read_file.readlines()\n",
    "    read_file.close()\n",
    "    return lines\n",
    "\n",
    "\n",
    "def write_inp (name, orig_inp):\n",
    "    write_file = open(name,'w')\n",
    "    for line in orignal_inp:\n",
    "        write_file.write(line)\n",
    "    write_file.close()\n",
    "\n",
    "    \n",
    "    \n",
    "def storage_curve_design(name,safety_factor, return_period, rain_duration, depth):\n",
    "    #safety_factor = 1.2 klk\n",
    "    #return_period = 5\n",
    "    #rain_duration = 240\n",
    "    \n",
    "    storage_nodes = []\n",
    "    curve_nodes = []\n",
    "    total_imperv = total_area_lenght_all(name)\n",
    "    total_imperv.rename(columns = {'Connected_nodeid':\"Node_ID\"}, inplace = True)\n",
    "    d =pd.merge(node_id(name), total_imperv, how = \"right\", on='Node_ID')\n",
    "    design_storage_area = storage_area_design(safety_factor, return_period, rain_duration, depth )\n",
    "    #storage_area_design(1.2, 5, 240, 2.5 )\n",
    "    \n",
    "    d = d.assign(storage_area=design_storage_area)\n",
    "    d =d.drop(d.index[d['OUTFALL']== 1]).reset_index()\n",
    "    for index, row in d.iterrows():\n",
    "        new_line = f\"{row['Node_ID']} STORAGE {depth} {row['storage_area']} \\n\"\n",
    "        curve_nodes.append(new_line)\n",
    "        new_line = f\"{row['Node_ID']} {row['Elevation']} {depth} 0 TABULAR {row['Node_ID']} 0 0 \\n\"\n",
    "        storage_nodes.append(new_line)\n",
    "    return (storage_nodes, curve_nodes, d, design_storage_area)\n",
    "\n",
    "\n",
    "# to find index number for a given phrase\n",
    "def index_num_phrase (list_name, phrase):\n",
    "    line_number = \"Phrase not found\"\n",
    "    for number, line in enumerate(list_name):\n",
    "        if phrase in line:\n",
    "            line_number = number\n",
    "            break\n",
    "            a_file.close()\n",
    "    return line_number\n",
    "\n",
    "\n",
    "# check if nodes are flooding and calculating total flooding if flooding exist\n",
    "def sum_flood (rpt):\n",
    "    nodes_flooded_loop =read_max_flood(rpt)\n",
    "    flood_sum = nodes_flooded_loop['Total_flood_volume'].sum()\n",
    "    return flood_sum\n",
    "\n",
    "# to get list of indexes from a list\n",
    "def index_list (list_):\n",
    "    index_list = []\n",
    "    for i in range(len(list_)):\n",
    "        index_list.append(i)\n",
    "    return index_list\n",
    "\n",
    "def creat_chromosome_index (selected_storages, storage_design):\n",
    "    chromosome = []\n",
    "    chromosome_index = []\n",
    "    index = -1\n",
    "    for i in storage_design:\n",
    "        index+=1\n",
    "        if i in list(list(selected_storages)):\n",
    "            chromosome. append (True)\n",
    "            chromosome_index.append(index)\n",
    "        else:\n",
    "            chromosome.append(False)\n",
    "    return (chromosome, chromosome_index)\n",
    "\n",
    "def storage_selection_first(storage_design):\n",
    "    nodes_flooded_loop =read_max_flood(rpt)\n",
    "\n",
    "    nodes_flooded = total_imperv_area(name)[total_imperv_area(name)[\"Connected_nodeid\"].isin(nodes_flooded_loop['Node'])]\n",
    "    selected_storages = nodes_flooded\n",
    "    chromosome_creat = creat_chromosome_index(selected_storages[\"Connected_nodeid\"], storage_design)\n",
    "    selected_storage_list = [storage_list_for_allnodes[i] for i in chromosome_creat[1]]\n",
    "\n",
    "    storage_list_for_allnodes_probabilty = []\n",
    "    for i in storage_list_for_allnodes_index:\n",
    "        if i in chromosome_creat[1]:\n",
    "            storage_list_for_allnodes_probabilty.append(50)\n",
    "        else:\n",
    "            storage_list_for_allnodes_probabilty.append(50)\n",
    "    return (selected_storage_list, chromosome_creat, storage_list_for_allnodes_probabilty, selected_storages)\n",
    "\n",
    "\n",
    "def storage_selection_iter(nodes_flooded_ini, storage_list_for_allnodes_index, storage_list_for_allnodes_probabilty, storage_design):\n",
    "\n",
    "    number_of_storage= random.randint(len(nodes_flooded_ini),len(nodes_flooded_ini)+3)\n",
    "    Set = set(storage_list_for_allnodes_index)\n",
    "    selected_storages_index =list(set(random.choices(list(Set),weights= storage_list_for_allnodes_probabilty, k = number_of_storage)))\n",
    "    selected_storage_list = [storage_list_for_allnodes[i] for i in selected_storages_index] \n",
    "    column_type = {'Connected_nodeid': str,  'Elev.': float ,\"MaxDepth\": float, 'InitDepth': float, \"Shape\": str, \"Curve_Name/Params\": str, \"N/A\": float, \"Fevap\": float}        \n",
    "    selected_storages = to_dataframe_dtype(selected_storage_list, column_type )\n",
    "    chromosome_creat = creat_chromosome_index(selected_storages[\"Connected_nodeid\"], storage_design)\n",
    "    return(selected_storage_list, chromosome_creat, selected_storages)\n",
    "\n",
    "#delete assigned storage nodes from juntion list and assign them to a new variabl\n",
    "def del_storage_from_junction (junction_orig, selected_storages):\n",
    "    new_junctions = junction_orig.copy()\n",
    "    storage_index_for_junction = []\n",
    "    for i in selected_storages[\"Connected_nodeid\"]:\n",
    "        storage_index_for_junction.append(int(node_id_ini[node_id_ini[\"Node_ID\"]== i].index.values))\n",
    "    return [i for j, i in enumerate(new_junctions) if j not in storage_index_for_junction]\n",
    "\n",
    "\n",
    "def creat_population (num):\n",
    "    \n",
    "\n",
    "    n=0\n",
    "    storage_nodes = []\n",
    "    flood = []\n",
    "    storage_area_total = []\n",
    "    chromosom = []\n",
    "    \n",
    "    while n<num:\n",
    " \n",
    "        # check if nodes are flooding and calculating total flooding if flooding exist\n",
    "        flood_sum = sum_flood(rpt)\n",
    "\n",
    "\n",
    "        if n== 0:\n",
    "            storages = storage_selection_first(d[2][\"Node_ID\"])\n",
    "            selected_storages = storages[3]\n",
    "            prob = storages[2]\n",
    "        else:\n",
    "            storages = storage_selection_iter(nodes_flooded_ini, storage_list_for_allnodes_index, prob, d[2][\"Node_ID\"])\n",
    "            selected_storages = storages[2]\n",
    "        \n",
    "\n",
    "        storage_nodes.append(selected_storages[\"Connected_nodeid\"])\n",
    "        flood.append(flood_sum)\n",
    "        storage_area_total.append(d[2][\"storage_area\"][storages[1][1]].sum())\n",
    "        chromosom.append(storages[1][0])\n",
    "        \n",
    "        \n",
    "        pd.set_option('display.max_rows', None, 'display.max_columns', None)\n",
    "\n",
    "        #delete assigned storage nodes from juntion list and assign them to a new variabl\n",
    "\n",
    "        new_junctions = del_storage_from_junction(junction_orig, selected_storages)\n",
    "\n",
    "        add_to_inp(\"[STORAGE]\",\"[CONDUITS]\", storages[0])\n",
    "        add_to_inp(\"[JUNCTIONS]\",\"[OUTFALLS]\", new_junctions)\n",
    "\n",
    "        n+=1\n",
    "        print(\"Creating Population...\")\n",
    "\n",
    "        ax.set_xlim(-1000, n)    \n",
    "        ax.cla()\n",
    "        ax.scatter(flood, storage_area_total, marker='o', label = \"Population\")\n",
    "        ax.set_ylim(bottom = -100)\n",
    "\n",
    "        ax.set_title(\"Initial Population\")\n",
    "        #ax.set_xlabel (\" total flood rate [l/s]\")\n",
    "        ax.set_ylabel(\"total storage area [m2]\")\n",
    "        ax.legend()\n",
    "        \n",
    "        #ax.set_xlim(left = 0, right = 160) \n",
    "        display(fig)    \n",
    "        clear_output(wait = True)\n",
    "        plt.pause(2) \n",
    "    display(fig)\n",
    "    print(\"Population created :)\")\n",
    "    write_inp (name, orignal_inp)\n",
    "    return (storage_nodes, flood, storage_area_total, chromosom)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb162662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SWMM file name, If this file is not in the same folder as the python file, the exact path should be given (its recommended to use same folder for swmm and python files)\n",
    "name = 'STRASSBERG_10T_120D.inp' \n",
    "\n",
    "# raingage file name\n",
    "raingage_name = \"Euler_II_10T_120D.dat\" \n",
    "\n",
    "#report file name (same name as swmm file name but diffrent extention)\n",
    "rpt= \"STRASSBERG_10T_120D.rpt\" \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f1d7fb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in (\"[SUBCATCHMENTS]\", \"[SUBAREAS]\", \"[INFILTRATION]\", \"[JUNCTIONS]\", \"[OUTFALLS]\", \"[CONDUITS]\", \"[XSECTIONS]\", \"[COORDINATES]\", \"[VERTICES]\", \"[Polygons]\" ):\n",
    "    del_line_range(name, line_num(name, i)+1, line_num(name, i)+3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bddd18c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add raingage if the file was opened for the first time \n",
    "add_raingage(name, raingage_name) \n",
    "# orignal file\n",
    "conduites = read_conduites(name)\n",
    "word_count= pd.value_counts(conduites['To_Node'])\n",
    "\n",
    "# copy of original junctions befor changing them\n",
    "junction_orig = select_data_range(name, line_num(name, \"[JUNCTIONS]\")+1, line_num(name, \"[OUTFALLS]\"))\n",
    "\n",
    "# create list of all curves and storage designes for all available nodes. storage_curve_design(name of the swmm file,safety_factor, return_period, rain_duration, depth of storage tank)\n",
    "d = storage_curve_design(name, 1.2, 10, 240, 2.5)\n",
    "# list of storage design for all nodes avaialble \n",
    "storage_list_for_allnodes = d[0]\n",
    "\n",
    "#add curve to the inp \n",
    "add_to_inp(\"[CURVES]\", \"[REPORT]\", d[1])\n",
    "\n",
    "#get a copy of original swmm file\n",
    "orignal_inp = read_inp(name)\n",
    "\n",
    "#dataframe for nodes which were flooded initialy after first run of the model\n",
    "nodes_flooded_ini = read_max_flood(rpt)\n",
    "\n",
    "best_flood_sum = float('inf')\n",
    "\n",
    "node_id_ini = node_id(name)\n",
    "\n",
    "\n",
    "# to get list of indexes for available nodes\n",
    "storage_list_for_allnodes_index = index_list(storage_list_for_allnodes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ff4dff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "from pymoo.algorithms.moo.nsga2 import NSGA2\n",
    "\n",
    "from pymoo.core.problem import ElementwiseProblem\n",
    "\n",
    "class MyProblem(ElementwiseProblem):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__(n_var = len(d[0]), \n",
    "                         n_obj=2)\n",
    "\n",
    "    def _evaluate(self, x, out, *args, **kwargs):\n",
    "        new_child_storage = read_chromosome(x)\n",
    "        column_type = {'Connected_nodeid': str,  'Elev.': float ,\"MaxDepth\": float, 'InitDepth': float, \"Shape\": str, \"Curve_Name/Params\": str, \"N/A\": float, \"Fevap\": float}\n",
    "        storages_dataFrame = to_dataframe_dtype(new_child_storage[0], column_type )\n",
    "        storages_id = storages_dataFrame[\"Connected_nodeid\"]\n",
    "        new_junctions = del_storage_from_junction(junction_orig, storages_dataFrame)\n",
    "        add_to_inp(\"[STORAGE]\",\"[CONDUITS]\", new_child_storage[0])\n",
    "        add_to_inp(\"[JUNCTIONS]\",\"[OUTFALLS]\", new_junctions)\n",
    "        f1 = flood_sum = sum_flood(rpt)\n",
    "        f2 = storage_area_total=d[2][\"storage_area\"][new_child_storage[1]].sum()\n",
    "        write_inp (name, orignal_inp)\n",
    "        out[\"F\"] = [f1, f2]\n",
    "\n",
    "\n",
    "\n",
    "problem = MyProblem()\n",
    "# to read the result from saved pickle file\n",
    "with open('res_1_4.pickle', 'rb') as f:\n",
    "     res_1= pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88190379",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[21000.        ,    49.01733824],\n",
       "       [    0.        ,   292.91940918],\n",
       "       [19000.        ,    53.93567698],\n",
       "       [13000.        ,   147.85277714],\n",
       "       [28000.        ,    33.954349  ],\n",
       "       [ 9000.        ,   170.39031894]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_1.F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6dc06bbd",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'read_chromosome' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-767cb6e89516>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mres_1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mnodes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mread_chromosome\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m         \u001b[0mnodes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mall_nodes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnodes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'read_chromosome' is not defined"
     ]
    }
   ],
   "source": [
    "# to make a dataframe and excel file for the pareto-front with their respective Selected nodes as storage-tank, Total flooded volume, and total storage tank area [m2]\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "all_nodes = []\n",
    "all_nodes_list = []\n",
    "for i in (res_1.X):\n",
    "    nodes = []\n",
    "    for n in read_chromosome(i)[0]:\n",
    "        nodes.append(n.split()[0])\n",
    "    all_nodes.append(str(nodes))\n",
    "    all_nodes_list.append(nodes)\n",
    "flooded = pd.DataFrame(all_nodes, columns = ({\"Selected nodes as storage tank\"}))\n",
    "\n",
    "flood_v = []\n",
    "storage_a = []\n",
    "for f in res_1.F:\n",
    "    flood_v.append(f[0])\n",
    "    storage_a.append(f[1])\n",
    "storage_a\n",
    "flooded[\"Total flooded volume [L]\"] = flood_v\n",
    "flooded[\"Total storage tank area [m2]\"]= storage_a\n",
    "\n",
    "flooded.to_excel(\"flooded_.xlsx\")\n",
    "flooded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a89503b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_nodes_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "6f6c450e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#new junctions\n",
    "new_junctions = junction_orig.copy()\n",
    "storage_index_for_junction = []\n",
    "for i in all_nodes_list[5]:\n",
    "    storage_index_for_junction.append(int((node_id_ini[node_id_ini[\"Node_ID\"]== i].index.values).astype(int)))\n",
    "new_junctions = [i for j, i in enumerate(new_junctions) if j not in storage_index_for_junction]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "346fcbce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(int((node_id_ini[node_id_ini[\"Node_ID\"]== i].index.values).astype(int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "9fc76bed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s =(node_id_ini[node_id_ini[\"Node_ID\"]== i].index.values)\n",
    "z = int(s)\n",
    "type (s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "92600a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#index for storages\n",
    "splited = []\n",
    "for elem in storage_list_for_allnodes:\n",
    "    splited.append(elem.split( ))\n",
    "index_storge= []\n",
    "for i in splited:\n",
    "    if i[0] in all_nodes_list[5]:\n",
    "        index_storge.append(splited.index(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "decaf78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_storage_list = [storage_list_for_allnodes[i] for i in index_storge]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "cd0d9ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_to_inp(\"[STORAGE]\",\"[CONDUITS]\", selected_storage_list)\n",
    "add_to_inp(\"[JUNCTIONS]\",\"[OUTFALLS]\", new_junctions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "ce5daeb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#open file1 in reading mode\n",
    "file1 = open(name, 'r')\n",
    "\n",
    "#open file2 in writing mode\n",
    "file2 = open('test.inp','w')\n",
    "\n",
    "#read from file1 and write to file2 using read method\n",
    "file2.write(file1.read())\n",
    "\n",
    "#close file1 and file2\n",
    "file1.close()\n",
    "file2.close()\n",
    "write_inp (name, orignal_inp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "b32ce8a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Node</th>\n",
       "      <th>HoursFlooded</th>\n",
       "      <th>Maximum_rate_LPS</th>\n",
       "      <th>days</th>\n",
       "      <th>hours</th>\n",
       "      <th>min</th>\n",
       "      <th>Total_flood_volume</th>\n",
       "      <th>Maximum_ponded_depth_meters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1002</td>\n",
       "      <td>0.02</td>\n",
       "      <td>7.69</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1003</td>\n",
       "      <td>0.02</td>\n",
       "      <td>83.65</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1019</td>\n",
       "      <td>0.09</td>\n",
       "      <td>68.82</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>18000.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1024</td>\n",
       "      <td>1.91</td>\n",
       "      <td>20.93</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>14000.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1030</td>\n",
       "      <td>0.08</td>\n",
       "      <td>53.56</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>13000.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>1490</td>\n",
       "      <td>0.01</td>\n",
       "      <td>27.71</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>1493</td>\n",
       "      <td>0.07</td>\n",
       "      <td>33.76</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>1496</td>\n",
       "      <td>0.04</td>\n",
       "      <td>8.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>1505</td>\n",
       "      <td>0.07</td>\n",
       "      <td>68.96</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>8000.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>1390</td>\n",
       "      <td>0.03</td>\n",
       "      <td>282.31</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>15000.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>112 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Node  HoursFlooded  Maximum_rate_LPS  days  hours   min  \\\n",
       "0    1002          0.02              7.69   1.0   12.0  39.0   \n",
       "1    1003          0.02             83.65   1.0   12.0  39.0   \n",
       "2    1019          0.09             68.82   1.0   12.0  40.0   \n",
       "3    1024          1.91             20.93   1.0   12.0  39.0   \n",
       "4    1030          0.08             53.56   1.0   12.0  40.0   \n",
       "..    ...           ...               ...   ...    ...   ...   \n",
       "107  1490          0.01             27.71   1.0   12.0  38.0   \n",
       "108  1493          0.07             33.76   1.0   12.0  37.0   \n",
       "109  1496          0.04              8.50   1.0   12.0  40.0   \n",
       "110  1505          0.07             68.96   1.0   12.0  36.0   \n",
       "111  1390          0.03            282.31   1.0   12.0  40.0   \n",
       "\n",
       "     Total_flood_volume  Maximum_ponded_depth_meters  \n",
       "0                   0.0                          0.0  \n",
       "1                3000.0                          0.0  \n",
       "2               18000.0                          0.0  \n",
       "3               14000.0                          0.0  \n",
       "4               13000.0                          0.0  \n",
       "..                  ...                          ...  \n",
       "107                 0.0                          0.0  \n",
       "108              6000.0                          0.0  \n",
       "109              1000.0                          0.0  \n",
       "110              8000.0                          0.0  \n",
       "111             15000.0                          0.0  \n",
       "\n",
       "[112 rows x 8 columns]"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_model(\"name.inp\")\n",
    "f= read_max_flood(\"name.rpt\")\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "3a01bbe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1120000.0"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_flood(rpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "b15b7222",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Connected_nodeid</th>\n",
       "      <th>connected catchment area [ha]</th>\n",
       "      <th>longest_path</th>\n",
       "      <th>longest_path_lenght</th>\n",
       "      <th>total_area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.129</td>\n",
       "      <td>[1006, 1000]</td>\n",
       "      <td>140.288</td>\n",
       "      <td>0.322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1001</td>\n",
       "      <td>0.210</td>\n",
       "      <td>[1002, 1001, 1025, 1026, 1018, 1024]</td>\n",
       "      <td>555.159</td>\n",
       "      <td>1.951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1002</td>\n",
       "      <td>0.139</td>\n",
       "      <td>[1036, 1002, 1001, 1025, 1026, 1018, 1024]</td>\n",
       "      <td>567.068</td>\n",
       "      <td>1.991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1003</td>\n",
       "      <td>0.049</td>\n",
       "      <td>[1037, 1036, 1002, 1001, 1025, 1026, 1018, 1024]</td>\n",
       "      <td>676.849</td>\n",
       "      <td>2.237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1005</td>\n",
       "      <td>0.087</td>\n",
       "      <td>[1038, 1039, 1010, 1011, 1012]</td>\n",
       "      <td>163.940</td>\n",
       "      <td>0.519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1006</td>\n",
       "      <td>0.193</td>\n",
       "      <td>[1044, 1004]</td>\n",
       "      <td>78.107</td>\n",
       "      <td>0.124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1007</td>\n",
       "      <td>0.182</td>\n",
       "      <td>[1002, 1001, 1025, 1026, 1018, 1024]</td>\n",
       "      <td>555.159</td>\n",
       "      <td>1.951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1008</td>\n",
       "      <td>0.300</td>\n",
       "      <td>[1001, 1025, 1026, 1018, 1024]</td>\n",
       "      <td>474.402</td>\n",
       "      <td>1.490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1009</td>\n",
       "      <td>0.572</td>\n",
       "      <td>[1025, 1026, 1018, 1024]</td>\n",
       "      <td>369.156</td>\n",
       "      <td>1.193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1010</td>\n",
       "      <td>0.068</td>\n",
       "      <td>[1040, 1037, 1036, 1002, 1001, 1025, 1026, 1018, 1024]</td>\n",
       "      <td>736.396</td>\n",
       "      <td>2.727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1011</td>\n",
       "      <td>0.055</td>\n",
       "      <td>[1021, 1040, 1037, 1036, 1002, 1001, 1025, 1026, 1018, 1024]</td>\n",
       "      <td>783.641</td>\n",
       "      <td>2.823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1012</td>\n",
       "      <td>0.019</td>\n",
       "      <td>[1041, 1021, 1040, 1037, 1036, 1002, 1001, 1025, 1026, 1018, 1024]</td>\n",
       "      <td>796.236</td>\n",
       "      <td>4.811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1014</td>\n",
       "      <td>0.242</td>\n",
       "      <td>[1009, 1022, 1034]</td>\n",
       "      <td>502.960</td>\n",
       "      <td>0.825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1015</td>\n",
       "      <td>0.011</td>\n",
       "      <td>[1039, 1010, 1011, 1012]</td>\n",
       "      <td>157.107</td>\n",
       "      <td>0.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1016</td>\n",
       "      <td>0.066</td>\n",
       "      <td>[1010, 1011, 1012]</td>\n",
       "      <td>123.129</td>\n",
       "      <td>0.142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1017</td>\n",
       "      <td>0.016</td>\n",
       "      <td>[1011, 1012]</td>\n",
       "      <td>38.988</td>\n",
       "      <td>0.074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1018</td>\n",
       "      <td>0.093</td>\n",
       "      <td>[1005, 1013]</td>\n",
       "      <td>39.002</td>\n",
       "      <td>0.087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1019</td>\n",
       "      <td>0.010</td>\n",
       "      <td>[1001, 1025, 1026, 1018, 1024]</td>\n",
       "      <td>474.402</td>\n",
       "      <td>1.490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1020</td>\n",
       "      <td>0.046</td>\n",
       "      <td>[1043, 1014, 1009, 1022]</td>\n",
       "      <td>275.771</td>\n",
       "      <td>1.098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1021</td>\n",
       "      <td>0.096</td>\n",
       "      <td>[1014, 1009, 1022, 1034]</td>\n",
       "      <td>611.916</td>\n",
       "      <td>1.133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1022</td>\n",
       "      <td>0.115</td>\n",
       "      <td>[1019, 1041, 1021, 1040, 1037, 1036, 1002, 1001, 1025, 1026, 1018, 1024]</td>\n",
       "      <td>820.955</td>\n",
       "      <td>4.883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1023</td>\n",
       "      <td>0.046</td>\n",
       "      <td>[1029, 1015]</td>\n",
       "      <td>84.175</td>\n",
       "      <td>0.150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1024</td>\n",
       "      <td>0.028</td>\n",
       "      <td>[1007, 1029, 1015]</td>\n",
       "      <td>105.708</td>\n",
       "      <td>0.332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1025</td>\n",
       "      <td>0.339</td>\n",
       "      <td>[1014, 1009, 1022, 1034]</td>\n",
       "      <td>611.916</td>\n",
       "      <td>1.133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1026</td>\n",
       "      <td>0.214</td>\n",
       "      <td>[1008, 1035]</td>\n",
       "      <td>12.557</td>\n",
       "      <td>0.364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1027</td>\n",
       "      <td>0.036</td>\n",
       "      <td>[1020, 1017]</td>\n",
       "      <td>209.110</td>\n",
       "      <td>0.062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1028</td>\n",
       "      <td>0.003</td>\n",
       "      <td>[1026, 1018, 1024]</td>\n",
       "      <td>147.446</td>\n",
       "      <td>0.335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1029</td>\n",
       "      <td>0.072</td>\n",
       "      <td>[1027, 1019, 1041, 1021, 1040, 1037, 1036, 1002, 1001, 1025, 1026, 1018, 1024]</td>\n",
       "      <td>840.241</td>\n",
       "      <td>4.919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1030</td>\n",
       "      <td>0.067</td>\n",
       "      <td>[1019, 1041, 1021, 1040, 1037, 1036, 1002, 1001, 1025, 1026, 1018, 1024]</td>\n",
       "      <td>820.955</td>\n",
       "      <td>4.883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1031</td>\n",
       "      <td>0.012</td>\n",
       "      <td>[1022, 1034]</td>\n",
       "      <td>400.000</td>\n",
       "      <td>0.253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1033</td>\n",
       "      <td>0.063</td>\n",
       "      <td>[1042, 1043, 1014, 1009, 1022, 1034]</td>\n",
       "      <td>683.942</td>\n",
       "      <td>1.913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1034</td>\n",
       "      <td>0.092</td>\n",
       "      <td>[1018, 1024]</td>\n",
       "      <td>41.756</td>\n",
       "      <td>0.121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1035</td>\n",
       "      <td>0.064</td>\n",
       "      <td>[1025, 1026, 1018, 1024]</td>\n",
       "      <td>369.156</td>\n",
       "      <td>1.193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1036</td>\n",
       "      <td>0.040</td>\n",
       "      <td>[1028, 1027, 1019]</td>\n",
       "      <td>30.765</td>\n",
       "      <td>0.049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1037</td>\n",
       "      <td>0.197</td>\n",
       "      <td>[1029, 1015]</td>\n",
       "      <td>84.175</td>\n",
       "      <td>0.150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1038</td>\n",
       "      <td>0.132</td>\n",
       "      <td>[1031, 1032]</td>\n",
       "      <td>60.711</td>\n",
       "      <td>0.012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1039</td>\n",
       "      <td>0.046</td>\n",
       "      <td>[1039, 1010, 1011, 1012]</td>\n",
       "      <td>157.107</td>\n",
       "      <td>0.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1040</td>\n",
       "      <td>0.126</td>\n",
       "      <td>[1037, 1036, 1002, 1001, 1025, 1026, 1018, 1024]</td>\n",
       "      <td>676.849</td>\n",
       "      <td>2.237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1041</td>\n",
       "      <td>0.075</td>\n",
       "      <td>[1038, 1039, 1010, 1011, 1012]</td>\n",
       "      <td>163.940</td>\n",
       "      <td>0.519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1042</td>\n",
       "      <td>0.345</td>\n",
       "      <td>[1040, 1037, 1036, 1002, 1001, 1025, 1026, 1018, 1024]</td>\n",
       "      <td>736.396</td>\n",
       "      <td>2.727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1043</td>\n",
       "      <td>0.103</td>\n",
       "      <td>[1041, 1021, 1040, 1037, 1036, 1002, 1001, 1025, 1026, 1018, 1024]</td>\n",
       "      <td>796.236</td>\n",
       "      <td>4.811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1044</td>\n",
       "      <td>0.124</td>\n",
       "      <td>[1042, 1043, 1014, 1009, 1022, 1034]</td>\n",
       "      <td>683.942</td>\n",
       "      <td>1.913</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Connected_nodeid  connected catchment area [ha]  \\\n",
       "0              1000                          0.129   \n",
       "1              1001                          0.210   \n",
       "2              1002                          0.139   \n",
       "3              1003                          0.049   \n",
       "4              1005                          0.087   \n",
       "5              1006                          0.193   \n",
       "6              1007                          0.182   \n",
       "7              1008                          0.300   \n",
       "8              1009                          0.572   \n",
       "9              1010                          0.068   \n",
       "10             1011                          0.055   \n",
       "11             1012                          0.019   \n",
       "12             1014                          0.242   \n",
       "13             1015                          0.011   \n",
       "14             1016                          0.066   \n",
       "15             1017                          0.016   \n",
       "16             1018                          0.093   \n",
       "17             1019                          0.010   \n",
       "18             1020                          0.046   \n",
       "19             1021                          0.096   \n",
       "20             1022                          0.115   \n",
       "21             1023                          0.046   \n",
       "22             1024                          0.028   \n",
       "23             1025                          0.339   \n",
       "24             1026                          0.214   \n",
       "25             1027                          0.036   \n",
       "26             1028                          0.003   \n",
       "27             1029                          0.072   \n",
       "28             1030                          0.067   \n",
       "29             1031                          0.012   \n",
       "30             1033                          0.063   \n",
       "31             1034                          0.092   \n",
       "32             1035                          0.064   \n",
       "33             1036                          0.040   \n",
       "34             1037                          0.197   \n",
       "35             1038                          0.132   \n",
       "36             1039                          0.046   \n",
       "37             1040                          0.126   \n",
       "38             1041                          0.075   \n",
       "39             1042                          0.345   \n",
       "40             1043                          0.103   \n",
       "41             1044                          0.124   \n",
       "\n",
       "                                                                      longest_path  \\\n",
       "0                                                                     [1006, 1000]   \n",
       "1                                             [1002, 1001, 1025, 1026, 1018, 1024]   \n",
       "2                                       [1036, 1002, 1001, 1025, 1026, 1018, 1024]   \n",
       "3                                 [1037, 1036, 1002, 1001, 1025, 1026, 1018, 1024]   \n",
       "4                                                   [1038, 1039, 1010, 1011, 1012]   \n",
       "5                                                                     [1044, 1004]   \n",
       "6                                             [1002, 1001, 1025, 1026, 1018, 1024]   \n",
       "7                                                   [1001, 1025, 1026, 1018, 1024]   \n",
       "8                                                         [1025, 1026, 1018, 1024]   \n",
       "9                           [1040, 1037, 1036, 1002, 1001, 1025, 1026, 1018, 1024]   \n",
       "10                    [1021, 1040, 1037, 1036, 1002, 1001, 1025, 1026, 1018, 1024]   \n",
       "11              [1041, 1021, 1040, 1037, 1036, 1002, 1001, 1025, 1026, 1018, 1024]   \n",
       "12                                                              [1009, 1022, 1034]   \n",
       "13                                                        [1039, 1010, 1011, 1012]   \n",
       "14                                                              [1010, 1011, 1012]   \n",
       "15                                                                    [1011, 1012]   \n",
       "16                                                                    [1005, 1013]   \n",
       "17                                                  [1001, 1025, 1026, 1018, 1024]   \n",
       "18                                                        [1043, 1014, 1009, 1022]   \n",
       "19                                                        [1014, 1009, 1022, 1034]   \n",
       "20        [1019, 1041, 1021, 1040, 1037, 1036, 1002, 1001, 1025, 1026, 1018, 1024]   \n",
       "21                                                                    [1029, 1015]   \n",
       "22                                                              [1007, 1029, 1015]   \n",
       "23                                                        [1014, 1009, 1022, 1034]   \n",
       "24                                                                    [1008, 1035]   \n",
       "25                                                                    [1020, 1017]   \n",
       "26                                                              [1026, 1018, 1024]   \n",
       "27  [1027, 1019, 1041, 1021, 1040, 1037, 1036, 1002, 1001, 1025, 1026, 1018, 1024]   \n",
       "28        [1019, 1041, 1021, 1040, 1037, 1036, 1002, 1001, 1025, 1026, 1018, 1024]   \n",
       "29                                                                    [1022, 1034]   \n",
       "30                                            [1042, 1043, 1014, 1009, 1022, 1034]   \n",
       "31                                                                    [1018, 1024]   \n",
       "32                                                        [1025, 1026, 1018, 1024]   \n",
       "33                                                              [1028, 1027, 1019]   \n",
       "34                                                                    [1029, 1015]   \n",
       "35                                                                    [1031, 1032]   \n",
       "36                                                        [1039, 1010, 1011, 1012]   \n",
       "37                                [1037, 1036, 1002, 1001, 1025, 1026, 1018, 1024]   \n",
       "38                                                  [1038, 1039, 1010, 1011, 1012]   \n",
       "39                          [1040, 1037, 1036, 1002, 1001, 1025, 1026, 1018, 1024]   \n",
       "40              [1041, 1021, 1040, 1037, 1036, 1002, 1001, 1025, 1026, 1018, 1024]   \n",
       "41                                            [1042, 1043, 1014, 1009, 1022, 1034]   \n",
       "\n",
       "    longest_path_lenght  total_area  \n",
       "0               140.288       0.322  \n",
       "1               555.159       1.951  \n",
       "2               567.068       1.991  \n",
       "3               676.849       2.237  \n",
       "4               163.940       0.519  \n",
       "5                78.107       0.124  \n",
       "6               555.159       1.951  \n",
       "7               474.402       1.490  \n",
       "8               369.156       1.193  \n",
       "9               736.396       2.727  \n",
       "10              783.641       2.823  \n",
       "11              796.236       4.811  \n",
       "12              502.960       0.825  \n",
       "13              157.107       0.375  \n",
       "14              123.129       0.142  \n",
       "15               38.988       0.074  \n",
       "16               39.002       0.087  \n",
       "17              474.402       1.490  \n",
       "18              275.771       1.098  \n",
       "19              611.916       1.133  \n",
       "20              820.955       4.883  \n",
       "21               84.175       0.150  \n",
       "22              105.708       0.332  \n",
       "23              611.916       1.133  \n",
       "24               12.557       0.364  \n",
       "25              209.110       0.062  \n",
       "26              147.446       0.335  \n",
       "27              840.241       4.919  \n",
       "28              820.955       4.883  \n",
       "29              400.000       0.253  \n",
       "30              683.942       1.913  \n",
       "31               41.756       0.121  \n",
       "32              369.156       1.193  \n",
       "33               30.765       0.049  \n",
       "34               84.175       0.150  \n",
       "35               60.711       0.012  \n",
       "36              157.107       0.375  \n",
       "37              676.849       2.237  \n",
       "38              163.940       0.519  \n",
       "39              736.396       2.727  \n",
       "40              796.236       4.811  \n",
       "41              683.942       1.913  "
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_area_lenght_all(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2128928",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
